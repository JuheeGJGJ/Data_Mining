{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "DM_Assignment_5_20161578.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi0HXI_9M8lY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2f77be-69c4-4da7-cb1e-b62103586e7c"
      },
      "source": [
        "!pip install einops"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc6X4fRDKP-j"
      },
      "source": [
        "#구현하는 모델에서 쓰이는 모든 activation함수는 정의하여 드린 GELU 함수를 사용해야함.\n",
        "#MultiHeadAttention에서 Head로 나눌때, 이미지를 patch로자른후 sequence로 만들때 Rearrange함수를 사용하면 편리함.(사용하지 않으셔도 됩니다)\n",
        "#CIFAR10에 대한 test accuracy가 60프로 이상인 ViT모델을 만드시오.\n",
        "import tensorflow as tf\n",
        "from einops.layers.tensorflow import Rearrange\n",
        "from tensorflow.keras.activations import gelu\n",
        "GELU = lambda x : gelu(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrJci74oNV2m"
      },
      "source": [
        "#논문[1]에서 설명하는 MultiHeadAttention을 만들어라.\n",
        "class MultiHeadedAttention(tf.keras.Model):\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension)\n",
        "    def __init__(self, dimension, heads=8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.heads = heads\n",
        "        self.dimension = dimension\n",
        "\n",
        "        self.rearrange_QKV = Rearrange('batch_size n (head dim) -> batch_size head n dim', head = self.heads)\n",
        "        self.rearrange_output = Rearrange ('batch_size head n dim -> batch_size n (head dim)')\n",
        "\n",
        "        self.wQ = tf.keras.layers.Dense(dimension)\n",
        "        self.wK = tf.keras.layers.Dense(dimension)\n",
        "        self.wV = tf.keras.layers.Dense(dimension)\n",
        "\n",
        "        self.linear = tf.keras.layers.Dense(dimension)\n",
        "        ############################################\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        \n",
        "        # Linear Q, K, V + Rearrange Q, K, V \n",
        "        Q = self.rearrange_QKV (self.wQ (inputs))\n",
        "        K = self.rearrange_QKV (self.wK (inputs))\n",
        "        V = self.rearrange_QKV (self.wV (inputs))\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        output = tf.matmul(Q, K, transpose_b = True) * (self.dimension ** (-1/2))\n",
        "        output = tf.nn.softmax (output)\n",
        "        output = tf.matmul (output, V)\n",
        "\n",
        "        output = self.rearrange_output(output)\n",
        "        output = self.linear (output)\n",
        "        ############################################\n",
        "        return output\n",
        "\n",
        "#인자로 받은 residual_function을 사용하여 real_function값을 return하여주는 Class를 만들어라.(call함수 참고)\n",
        "class ResidualBlock(tf.keras.Model):\n",
        "    def __init__(self, residual_function):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.residual_function = residual_function\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.residual_function(inputs) + inputs\n",
        "\n",
        "#인자로 받은 normfunction에 들어가기전에 LayerNormalization을 해주는 Class를 만들어라.(call함수 참고)\n",
        "class NormalizationBlock(tf.keras.Model):\n",
        "    def __init__(self, norm_function, epsilon=1e-5):\n",
        "        super(NormalizationBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.norm_function = norm_function\n",
        "        self.normalize = tf.keras.layers.LayerNormalization(epsilon=epsilon)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.norm_function(self.normalize(inputs))\n",
        "\n",
        "#논문[1]에서의 MLPBlock을 만들어라.\n",
        "class MLPBlock(tf.keras.Model):\n",
        "    #output_dimension - MLPBlock의 output dimension\n",
        "    #hidden_dimension - MLPBlock의 hidden layer dimension\n",
        "    def __init__(self, output_dimension, hidden_dimension):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.linear1 = tf.keras.layers.Dense(hidden_dimension)\n",
        "        self.linear2 = tf.keras.layers.Dense(output_dimension)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        output = self.linear1 (inputs)\n",
        "        output= GELU (output)\n",
        "        output = self.linear2 (output)\n",
        "        output= GELU (output)\n",
        "        ############################################\n",
        "        return output\n",
        "\n",
        "#논문[1]을 읽고 TransformerEncoder를 위에서 정의한 class들을 사용하여 만들어라.\n",
        "class TransformerEncoder(tf.keras.Model):\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), heads - MHA에서 head의 개수\n",
        "    #depth - encoder layer의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension): \n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        layers_ = []\n",
        "        for _ in range(depth):\n",
        "            ############Write your code Here############\n",
        "            layers_ += [\n",
        "                        ResidualBlock (\n",
        "                            NormalizationBlock (\n",
        "                                MultiHeadedAttention (dimension, heads)\n",
        "                            )\n",
        "                        ), \n",
        "\n",
        "                        ResidualBlock (\n",
        "                            NormalizationBlock (\n",
        "                                MLPBlock (dimension, mlp_dimension)\n",
        "                            )\n",
        "                        )\n",
        "            ]\n",
        "            ############################################\n",
        "        self.layers_ = tf.keras.Sequential(layers_)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layers_(inputs)\n",
        "\n",
        "#논문[2]를 읽고 ViT모델을 위에서 정의한 class들을 사용하여 만들어라.\n",
        "class ImageTransformer(tf.keras.Model):\n",
        "    #image_size - 이미지의 W==H의 크기(int), patch_size - 이미지를 쪼갤 patch의 크기(int)\n",
        "    #n_classes - 최종 class의 개수, batch_size - 배치사이즈\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), depth - encoder layer의 개수\n",
        "    #heads - MHA에서 head의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
        "    #channel - input image에 대한 channel의 수\n",
        "    def __init__(\n",
        "            self, image_size, patch_size, n_classes, batch_size,\n",
        "            dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.positional_embedding = self.add_weight(\n",
        "            \"position_embeddings\", shape=[num_patches + 1, dimension],\n",
        "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
        "        )\n",
        "        self.classification_token = self.add_weight(\n",
        "            \"classification_token\", shape=[1, 1, dimension],\n",
        "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
        "        )\n",
        "        ############Write your code Here############\n",
        "        self.rearrange_patch = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)'\n",
        "                                          , p1 = self.patch_size, p2 = self.patch_size)\n",
        "        self.project = tf.keras.layers.Dense(dimension) \n",
        "\n",
        "        self.transformer = TransformerEncoder (dimension, depth, heads, mlp_dimension)\n",
        "\n",
        "        self.mlp_head = tf.identity\n",
        "        self.mlp = tf.keras.layers.Dense(mlp_dimension)\n",
        "        \n",
        "        self.linear = tf.keras.layers.Dense(n_classes)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Linear Projection of Flattened Patches\n",
        "        output = self.rearrange_patch (inputs)\n",
        "        output = self.project (output)\n",
        "\n",
        "        cls_tokens = tf.broadcast_to (\n",
        "            self.classification_token,\n",
        "            [batch_size, 1, self.dimension]\n",
        "        )\n",
        "        output = tf.concat ([cls_tokens, output], axis = 1)\n",
        "\n",
        "        output += self.positional_embedding\n",
        "\n",
        "        # Transformer Encoder\n",
        "        output = self.transformer (output)\n",
        "        output = self.mlp_head (output[:, 0])\n",
        "        output = self.mlp (output)\n",
        "            \n",
        "        output = GELU (output)\n",
        "        output = self.linear (output)\n",
        "        ############################################\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAydwOELeFba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e79267a-cfe6-47f9-ef7f-c32ded3b9be6"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "# Download and prepare the CIFAR10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "############Write your code Here############\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "############################################\n",
        "\n",
        "# Make image shape (BS, H, W, C) to (BS, C, H, W)\n",
        "############Write your code Here############\n",
        "train_images = tf.transpose (train_images, perm = [0, 3, 1, 2]) \n",
        "test_images = tf.transpose (test_images, perm = [0, 3, 1, 2])\n",
        "############################################\n",
        "\n",
        "#Initialize your model\n",
        "#Initialize optimizer and loss and compile it to the model\n",
        "############Write your code Here############\n",
        "# one - hot encoding\n",
        "train_labels = tf.one_hot (train_labels, 10)\n",
        "train_labels = tf.squeeze (train_labels)\n",
        "test_labels = tf.one_hot (test_labels, 10)\n",
        "test_labels = tf.squeeze (test_labels)\n",
        "\n",
        "# initiailize model\n",
        "model = ImageTransformer(\n",
        "            image_size=32, patch_size=4, n_classes=10, batch_size=64,\n",
        "            dimension=64, depth=3, heads=4, mlp_dimension=128\n",
        "        )\n",
        "\n",
        "# initialize optimizer, loss, accuracy\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "accuracy = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "# compile model\n",
        "model.compile (optimizer = optimizer, loss = loss, metrics = accuracy)\n",
        "############################################\n",
        "\n",
        "#Train your model\n",
        "############Write your code Here############\n",
        "model.fit(train_images, train_labels, batch_size=64, epochs=15)\n",
        "\n",
        "# validation set\n",
        "#val_images = train_images[:10000]\n",
        "#train_images = train_images[10000:]\n",
        "#val_labels = train_labels[:10000]\n",
        "#train_labels = train_labels[10000:]\n",
        "\n",
        "#model.fit(train_images, train_labels, batch_size=64, epochs=20, validation_data = (val_images, val_labels))\n",
        "############################################\n",
        "print('==============Training Finished===============')\n",
        "\n",
        "#Evaluate your test samples\n",
        "accuracy = 0\n",
        "############Write your code Here############\n",
        "_, accuracy = model.evaluate(test_images, test_labels, batch_size=64)\n",
        "############################################\n",
        "\n",
        "print('Test Accuracy :', accuracy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 16s 15ms/step - loss: 1.7111 - accuracy: 0.3612\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.3782 - accuracy: 0.4966\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.2589 - accuracy: 0.5415\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.1870 - accuracy: 0.5705\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.1234 - accuracy: 0.5923\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 1.0751 - accuracy: 0.6095\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.0319 - accuracy: 0.6250\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9895 - accuracy: 0.6415\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9503 - accuracy: 0.6584\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.9161 - accuracy: 0.6688\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8812 - accuracy: 0.6828\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8483 - accuracy: 0.6920\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.8138 - accuracy: 0.7043\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7855 - accuracy: 0.7146\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7553 - accuracy: 0.7244\n",
            "==============Training Finished===============\n",
            "157/157 [==============================] - 3s 11ms/step - loss: 1.1490 - accuracy: 0.6117\n",
            "Test Accuracy : 0.6116999983787537\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}